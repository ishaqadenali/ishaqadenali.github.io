<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ishaq  Aden-Ali | Publications</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://raw.githubusercontent.com/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Theming-->




    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
       <span class="font-weight-bold">Ishaq</span>   Aden-Ali
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">Author order for papers marked with * are based on contribution. Otherwise, they are listed alphabetically which is the norm in theoretical computer science.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">COLT</abbr>
    
  
  </div>

  <div id="Majority-of-3" class="col-sm-8">
    
      <div class="title">Majority-of-Three: The Simplest Optimal Learner?</div>
      <div class="author">
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  Mikael Møller Høgsgaard,
                
              
            
          
        
          
            
              
                
                  <a href="https://cs.au.dk/~larsen/" target="_blank">Kasper Green Larsen</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://sites.google.com/view/nikitazhivotovskiy/" target="_blank">Nikita Zhivotovskiy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Learning Theory,</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2403.08831" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Developing an optimal PAC learning algorithm in the realizable setting, where empirical risk minimization (ERM) is suboptimal, was a major open problem in learning theory for decades. The problem was finally resolved by Hanneke a few years ago. Unfortunately, Hanneke’s algorithm is quite complex as it returns the majority vote of many ERM classifiers that are trained on carefully selected subsets of the data. It is thus a natural goal to determine the simplest algorithm that is optimal. In this work we study the arguably simplest algorithm that could be optimal: returning the majority vote of three ERM classifiers. We show that this algorithm achieves the optimal in-expectation bound on its error which is provably unattainable by a single ERM classifier. Furthermore, we prove a near-optimal high-probability bound on this algorithm’s error. We conjecture that a better analysis will prove that this algorithm is in fact optimal in the high-probability regime.
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">RANDOM</abbr>
    
  
  </div>

  <div id="Approximate-Counting" class="col-sm-8">
    
      <div class="title">On The Amortized Complexity of Approximate Counting</div>
      <div class="author">
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  <a href="https://yanjunhan2021.github.io/" target="_blank">Yanjun Han</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://people.eecs.berkeley.edu/~minilek/" target="_blank">Jelani Nelson</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://www.cs.princeton.edu/~hy2/" target="_blank">Huacheng Yu</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Randomization and Computation,</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2211.03917" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Naively storing a counter up to value n would require Ω(logn) bits of memory. Nelson and Yu [NY22], following work of [Morris78], showed that if the query answers need only be (1+ϵ)-approximate with probability at least 1−δ, then O(loglogn+loglog(1/δ)+log(1/ϵ)) bits suffice, and in fact this bound is tight. Morris’ original motivation for studying this problem though, as well as modern applications, require not only maintaining one counter, but rather k counters for k large. This motivates the following question: for k large, can k counters be simultaneously maintained using asymptotically less memory than k times the cost of an individual counter? That is to say, does this problem benefit from an improved \it amortized space complexity bound?
We answer this question in the negative. Specifically, we prove a lower bound for nearly the full range of parameters showing that, in terms of memory usage, there is no asymptotic benefit possible via amortization when storing multiple counters. Our main proof utilizes a certain notion of "information cost" recently introduced by Braverman, Garg and Woodruff in FOCS 2020 to prove lower bounds for streaming algorithms.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">FOCS</abbr>
    
  
  </div>

  <div id="One-Inclusion-Graph-Optimal" class="col-sm-8">
    
      <div class="title">Optimal PAC Bounds Without Uniform Convergence</div>
      <div class="author">
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  <a href="https://yeshwanth94.github.io/" target="_blank">Yeshwanth Cherapanamjeri</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://ashettyv.github.io/" target="_blank">Abhishek Shetty</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://sites.google.com/view/nikitazhivotovskiy/" target="_blank">Nikita Zhivotovskiy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Symposium on Foundations of Computer Science,</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2304.09167" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In statistical learning theory, determining the sample complexity of realizable binary classification for VC classes was a long-standing open problem. The results of Simon and Hanneke established sharp upper bounds in this setting. However, the reliance of their argument on the uniform convergence principle limits its applicability to more general learning settings such as multiclass classification. In this paper, we address this issue by providing optimal high probability risk bounds through a framework that surpasses the limitations of uniform convergence arguments.
Our framework converts the leave-one-out error of permutation invariant predictors into high probability risk bounds. As an application, by adapting the one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth, we propose an algorithm that achieves an optimal PAC bound for binary classification. Specifically, our result shows that certain aggregations of one-inclusion graph algorithms are optimal, addressing a variant of a classic question posed by Warmuth.

We further instantiate our framework in three settings where uniform convergence is provably suboptimal. For multiclass classification, we prove an optimal risk bound that scales with the one-inclusion hypergraph density of the class, addressing the suboptimality of the analysis of Daniely and Shalev-Shwartz. For partial hypothesis classification, we determine the optimal sample complexity bound, resolving a question posed by Alon, Hanneke, Holzman, and Moran. For realizable bounded regression with absolute loss, we derive an optimal risk bound that relies on a modified version of the scale-sensitive dimension, refining the results of Bartlett and Long. Our rates surpass standard uniform convergence-based results due to the smaller complexity measure in our risk bound.
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">COLT</abbr>
    
  
  </div>

  <div id="One-Inclusion-Graph-Not-Optimal" class="col-sm-8">
    
      <div class="title">The One-Inclusion Graph Algorithm is not Always Optimal</div>
      <div class="author">
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  <a href="https://yeshwanth94.github.io/" target="_blank">Yeshwanth Cherapanamjeri</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://ashettyv.github.io/" target="_blank">Abhishek Shetty</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://sites.google.com/view/nikitazhivotovskiy/" target="_blank">Nikita Zhivotovskiy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Learning Theory,</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2212.09270" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth achieves an optimal in-expectation risk bound in the standard PAC classification setup. In one of the first COLT open problems, Warmuth conjectured that this prediction strategy <i>always</i> implies an optimal high probability bound on the risk, and hence is also an optimal PAC algorithm. We refute this conjecture in the strongest sense: for any practically interesting Vapnik-Chervonenkis class, we provide an in-expectation optimal one-inclusion graph algorithm whose high probability risk bound cannot go beyond that implied by Markov’s inequality. Our construction of these poorly performing one-inclusion graph algorithms uses Varshamov-Tenengolts error correcting codes.

Our negative result has several implications. First, it shows that the same poor high-probability performance is inherited by several recent prediction strategies based on generalizations of the one-inclusion graph algorithm. Second, our analysis shows yet another statistical problem that enjoys an estimator that is provably optimal in expectation via a leave-one-out argument, but fails in the high-probability regime. This discrepancy occurs despite the boundedness of the binary loss for which arguments based on concentration inequalities often provide sharp high probability risk bounds.
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="Private-Mixtures" class="col-sm-8">
    
      <div class="title">Privately Learning Mixtures of Axis-Aligned Gaussians</div>
      <div class="author">
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.cas.mcmaster.ca/ashtiani/" target="_blank">Hassan Ashtiani</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://cvliaw.github.io/" target="_blank">Chris Liaw</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Neural Information Processing Systems,</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2106.02162" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ALT</abbr>
    
  
  </div>

  <div id="Private-Gaussians" class="col-sm-8">
    
      <div class="title">On the Sample Complexity of Privately Learning Unbounded High-Dimensional Gaussians</div>
      <div class="author">
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.cas.mcmaster.ca/ashtiani/" target="_blank">Hassan Ashtiani</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="http://www.gautamkamath.com" target="_blank">Gautam Kamath</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Algorithmic Learning Theory,</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2010.09929" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We provide sample complexity upper bounds for agnostically learning multivariate Gaussians under the constraint of approximate differential privacy. These are the first finite sample upper bounds for general Gaussians which do not impose restrictions on the parameters of the distribution. Our bounds are near-optimal in the case when the covariance is known to be the identity, and conjectured to be near-optimal in the general case. From a technical standpoint, we provide analytic tools for arguing the existence of global “locally small” covers from local covers of the space. These are exploited using modifications of recent techniques for differentially private hypothesis selection. Our techniques may prove useful for privately learning other distribution classes which do not possess a finite cover.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AISTATS</abbr>
    
  
  </div>

  <div id="SPNs" class="col-sm-8">
    
      <div class="title">On the Sample Complexity of Learning Sum-Product Networks</div>
      <div class="author">
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  and <a href="https://www.cas.mcmaster.ca/ashtiani/" target="_blank">Hassan Ashtiani</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Artificial Intelligence and Statistics,</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1912.02765" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sum-Product Networks (SPNs) can be regarded as a form of deep graphical models that compactly represent deeply factored and mixed distributions. An SPN is a rooted directed acyclic graph (DAG) consisting of a set of leaves (corresponding to base distributions), a set of sum nodes (which represent mixtures of their children distributions) and a set of product nodes (representing the products of its children distributions).
In this work, we initiate the study of the sample complexity of PAC-learning the set of distributions that correspond to SPNs. We show that the sample complexity of learning tree structured SPNs with the usual type of leaves (i.e., Gaussian or discrete) grows at most linearly (up to logarithmic factors) with the number of parameters of the SPN. More specifically, we show that the class of distributions that corresponds to tree structured Gaussian SPNs with k mixing weights and e (d-dimensional Gaussian) leaves can be learned within Total Variation error ε using at most Õ((ed²+k)/ε²) samples. A similar result holds for tree structured SPNs with discrete leaves.
We obtain the upper bounds based on the recently proposed notion of distribution compression schemes. More specifically, we show that if a (base) class of distributions ℱ admits an "efficient" compression, then the class of tree structured SPNs with leaves from ℱ also admits an efficient compression.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Optics" class="col-sm-8">
    
      <div class="title">Time-resolved diffuse optical tomography system using an accelerated inverse problem solver*</div>
      <div class="author">
        
          
            
              
                
                  Mrwan Alayed,
                
              
            
          
        
          
            
              
                
                  Mohamed Naser,
                
              
            
          
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  and <a href="http://www.ece.mcmaster.ca/faculty/deen/" target="_blank">M. Jamal Deen</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Optics Express,</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://www.osapublishing.org/oe/abstract.cfm?uri=oe-26-2-963" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SISPAD</abbr>
    
  
  </div>

  <div id="sispadCobaltGermanide" class="col-sm-8">
    
      <div class="title">Novel experimentally calibrated multiphase TCAD model for cobalt germanide growth*</div>
      <div class="author">
        
          
            
              
                
                  <a href="https://www.linkedin.com/in/mohamed-rabie-8536776/" target="_blank">Mohamed Rabie</a>,
                
              
            
          
        
          
            
              
                <em>Ishaq Aden-Ali</em>,
              
            
          
        
          
            
              
                
                  and <a href="http://www.ece.mcmaster.ca/~yaser/" target="_blank">Yaser Haddara</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Simulation of Semiconductor Processes and Devices,</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
    
    
      <a href=" https://ieeexplore.ieee.org/document/8085266" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Ishaq  Aden-Ali.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
